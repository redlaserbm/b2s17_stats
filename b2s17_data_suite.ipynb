{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import load_data as ld\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing Stats\n",
    "\n",
    "We build a Pandas Dataframe to track key stats for each player, with each row containing the following:\n",
    "- User ID\n",
    "- Username\n",
    "- Matches Played\n",
    "- Win %\n",
    "- Win % for *Each Tower*\n",
    "\n",
    "To add later:\n",
    "- Win % for each hero\n",
    "- Win % for each map\n",
    "\n",
    "The strategy here is to first build a dictionary with the keys being user ID's and the values being lists containing the other *47* parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the DataFrame With Dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When computing winrates, we will penalize winrates if the amount of games played is low. This ideally will help the AI make better decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_wr(x, n, stds = 1, iter = 25):\n",
    "    def foo(p, n):\n",
    "        return p + stds*(p*(1-p)/n)**0.5 - x\n",
    "    \n",
    "    a = 0\n",
    "    b = 1\n",
    "    for i in range(iter):\n",
    "        c = 0.5*(a + b)\n",
    "        if foo(c, n) > 0:\n",
    "            b = c\n",
    "        elif foo(c, n) < 0:\n",
    "            a = c\n",
    "        else:\n",
    "            return c\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's build a dictionary of all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "s17_player_stats = {}\n",
    "for i in range(len(ld.data)):\n",
    "    body = ld.data[i]['body']\n",
    "\n",
    "    players = ['playerLeft', 'playerRight']\n",
    "    towers = ['towerone', 'towertwo', 'towerthree']\n",
    "\n",
    "    for player in players:\n",
    "        player_side = body[player]\n",
    "        user_id = player_side['profileURL'][42:]\n",
    "        username = player_side['displayName']\n",
    "\n",
    "        # Create a new default entry if this is the first time we've come across this player\n",
    "        if user_id not in s17_player_stats.keys():\n",
    "            s17_player_stats[user_id] = [username]\n",
    "            s17_player_stats[user_id].extend([0 for i in range(46)])\n",
    "\n",
    "        # Increment the matches played by one\n",
    "        s17_player_stats[user_id][1] += 1\n",
    "\n",
    "        # If the player won, increment matches won by one\n",
    "        if player_side['result'] == 'win':\n",
    "            s17_player_stats[user_id][2] += 1\n",
    "\n",
    "        # Which towers did the player use?\n",
    "        for tower in towers:\n",
    "            # print(s17_player_stats[user_id][3])\n",
    "            s17_player_stats[user_id][2*ld.tower_encoding[player_side[tower]] + 3] += 1 # Matches played with a tower\n",
    "            if player_side['result'] == 'win': \n",
    "                s17_player_stats[user_id][2*ld.tower_encoding[player_side[tower]] + 4] += 1 # Matches won with a tower\n",
    "    \n",
    "for key in s17_player_stats.keys():\n",
    "    s17_player_stats[key][2] = s17_player_stats[key][2]/s17_player_stats[key][1] # Get overall winrate\n",
    "    i = 4\n",
    "    while i < len(s17_player_stats[key]):\n",
    "        try:\n",
    "            s17_player_stats[key][i] = adj_wr(s17_player_stats[key][i]/s17_player_stats[key][i-1], s17_player_stats[key][i-1])\n",
    "        except: \n",
    "            s17_player_stats[key][i] = 0.0 # Get winrate for each tower\n",
    "        s17_player_stats[key].pop(i-1)\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and build a dataset object based on what we have so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = '9fbf1e8e8dc3ada34d138d1f5625e375cf521aed9f448d39'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class S17(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        body = self.data[idx]['body']\n",
    "\n",
    "        players = ['playerLeft', 'playerRight']\n",
    "        towers = ['towerone', 'towertwo', 'towerthree']\n",
    "\n",
    "        x_tensor = []\n",
    "        for player in players:\n",
    "            player_id = body[player]['profileURL'][42:]\n",
    "            player_stats = s17_player_stats[player_id]\n",
    "\n",
    "            tower_wrs = []\n",
    "            for tower in towers:\n",
    "                # Retrieve the WR each player has with each of the towers they are playing.\n",
    "                tower_wrs.append(float(s17_player_stats[player_id][ld.tower_encoding[body[player][tower]] + 3]))\n",
    "\n",
    "            x_tensor.append(float(s17_player_stats[player_id][1])) #Matches Played\n",
    "            x_tensor.append(float(s17_player_stats[player_id][2])) #Overall WR\n",
    "            x_tensor.append(sum(tower_wrs)) # WRs with each tower\n",
    "\n",
    "        # Who won?\n",
    "        if body['playerRight']['result'] == 'win':\n",
    "            winner = 1\n",
    "        elif body['playerRight']['result'] == 'lose':\n",
    "            winner = 0\n",
    "        else:\n",
    "            winner = 0.5\n",
    "        \n",
    "        return torch.tensor(x_tensor), winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "s17_dataset = S17(ld.data)\n",
    "split = random_split(s17_dataset, [0.2,0.8])\n",
    "data_train = split[0]\n",
    "data_test = split[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, W]: torch.Size([64, 6])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "s17_train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "s17_test_loader = DataLoader(data_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for X, y in s17_test_loader:\n",
    "    print(f\"Shape of X [N, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (logistic): Sequential(\n",
      "    (0): Linear(in_features=6, out_features=6, bias=True)\n",
      "    (1): Linear(in_features=6, out_features=1, bias=True)\n",
      "    (2): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.logistic = nn.Sequential(nn.Linear(6,6), nn.Linear(6,1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.logistic(x)\n",
    "        return torch.flatten(y)\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-4)\n",
    "\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        # print(X,y)\n",
    "        pred = model(X)\n",
    "        # print(pred)\n",
    "        # print(y)\n",
    "        loss = loss_fn(pred, y.float())\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            # print(list(model.parameters())[0])\n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y.float()).item()\n",
    "            # print(torch.abs(torch.round(y - pred)))\n",
    "            # print(torch.tensor([1 for i in range(batch_size)]))\n",
    "            # print(torch.tensor([1 for i in range(y.size()[0])]) - torch.abs(torch.round(y - pred)))\n",
    "            a = torch.tensor([1 for i in range(y.size()[0])]).to(device)\n",
    "            b = torch.abs(torch.round(y - pred)).to(device)\n",
    "            correct += torch.sum(a - b)\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 141.400024  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2577,  0.1410, -0.0886, -0.1564, -0.1577, -0.1503],\n",
      "        [-0.2552, -0.2928,  0.1083,  0.1787, -0.2208,  0.0540],\n",
      "        [ 0.3549,  0.1834, -0.3723,  0.2425, -0.2120, -0.3731],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0333],\n",
      "        [ 0.0701,  0.2088,  0.3697,  0.1826,  0.3547, -0.0445],\n",
      "        [-0.3590,  0.0244, -0.1649, -0.2490, -0.2890,  0.2453]],\n",
      "       requires_grad=True)\n",
      "loss: 131.011566  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2577,  0.1410, -0.0886, -0.1565, -0.1577, -0.1503],\n",
      "        [-0.2552, -0.2928,  0.1083,  0.1787, -0.2207,  0.0540],\n",
      "        [ 0.3549,  0.1834, -0.3723,  0.2426, -0.2120, -0.3731],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0701,  0.2088,  0.3697,  0.1825,  0.3547, -0.0445],\n",
      "        [-0.3590,  0.0244, -0.1649, -0.2490, -0.2890,  0.2453]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.191035 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 133.084671  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2577,  0.1410, -0.0886, -0.1565, -0.1577, -0.1503],\n",
      "        [-0.2552, -0.2928,  0.1083,  0.1788, -0.2207,  0.0540],\n",
      "        [ 0.3549,  0.1834, -0.3723,  0.2427, -0.2120, -0.3731],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0701,  0.2088,  0.3697,  0.1824,  0.3547, -0.0445],\n",
      "        [-0.3590,  0.0244, -0.1649, -0.2491, -0.2890,  0.2452]],\n",
      "       requires_grad=True)\n",
      "loss: 108.131134  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2577,  0.1410, -0.0886, -0.1566, -0.1577, -0.1503],\n",
      "        [-0.2552, -0.2928,  0.1083,  0.1788, -0.2207,  0.0540],\n",
      "        [ 0.3549,  0.1834, -0.3723,  0.2428, -0.2120, -0.3730],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0701,  0.2088,  0.3697,  0.1823,  0.3547, -0.0445],\n",
      "        [-0.3590,  0.0244, -0.1649, -0.2492, -0.2890,  0.2452]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.191076 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 135.163666  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2577,  0.1410, -0.0886, -0.1566, -0.1577, -0.1503],\n",
      "        [-0.2552, -0.2928,  0.1083,  0.1789, -0.2207,  0.0540],\n",
      "        [ 0.3549,  0.1834, -0.3723,  0.2429, -0.2120, -0.3730],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0701,  0.2088,  0.3697,  0.1823,  0.3547, -0.0445],\n",
      "        [-0.3590,  0.0244, -0.1649, -0.2492, -0.2890,  0.2452]],\n",
      "       requires_grad=True)\n",
      "loss: 149.722595  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2578,  0.1410, -0.0886, -0.1567, -0.1577, -0.1503],\n",
      "        [-0.2552, -0.2928,  0.1083,  0.1789, -0.2207,  0.0541],\n",
      "        [ 0.3549,  0.1834, -0.3723,  0.2430, -0.2120, -0.3730],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0700,  0.2088,  0.3697,  0.1822,  0.3547, -0.0445],\n",
      "        [-0.3591,  0.0244, -0.1649, -0.2493, -0.2890,  0.2452]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.191043 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 141.398849  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2578,  0.1410, -0.0885, -0.1568, -0.1577, -0.1503],\n",
      "        [-0.2552, -0.2928,  0.1083,  0.1790, -0.2207,  0.0541],\n",
      "        [ 0.3549,  0.1834, -0.3723,  0.2430, -0.2120, -0.3730],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0700,  0.2088,  0.3697,  0.1821,  0.3547, -0.0445],\n",
      "        [-0.3590,  0.0244, -0.1649, -0.2493, -0.2890,  0.2452]],\n",
      "       requires_grad=True)\n",
      "loss: 149.717407  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2578,  0.1410, -0.0885, -0.1568, -0.1578, -0.1504],\n",
      "        [-0.2552, -0.2928,  0.1083,  0.1790, -0.2207,  0.0541],\n",
      "        [ 0.3549,  0.1834, -0.3723,  0.2431, -0.2120, -0.3730],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0700,  0.2088,  0.3697,  0.1820,  0.3547, -0.0445],\n",
      "        [-0.3591,  0.0244, -0.1649, -0.2494, -0.2890,  0.2452]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.191041 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 112.294617  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2578,  0.1410, -0.0885, -0.1569, -0.1578, -0.1504],\n",
      "        [-0.2552, -0.2928,  0.1083,  0.1791, -0.2207,  0.0541],\n",
      "        [ 0.3549,  0.1834, -0.3723,  0.2432, -0.2120, -0.3730],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0700,  0.2088,  0.3697,  0.1820,  0.3547, -0.0445],\n",
      "        [-0.3591,  0.0244, -0.1649, -0.2494, -0.2890,  0.2452]],\n",
      "       requires_grad=True)\n",
      "loss: 128.925369  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2578,  0.1410, -0.0885, -0.1569, -0.1578, -0.1504],\n",
      "        [-0.2552, -0.2928,  0.1083,  0.1791, -0.2207,  0.0541],\n",
      "        [ 0.3549,  0.1834, -0.3723,  0.2433, -0.2120, -0.3730],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0700,  0.2088,  0.3697,  0.1819,  0.3546, -0.0446],\n",
      "        [-0.3591,  0.0244, -0.1649, -0.2495, -0.2890,  0.2452]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.186500 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 145.534836  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2578,  0.1410, -0.0885, -0.1570, -0.1578, -0.1504],\n",
      "        [-0.2552, -0.2928,  0.1083,  0.1792, -0.2207,  0.0541],\n",
      "        [ 0.3549,  0.1834, -0.3723,  0.2433, -0.2120, -0.3730],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0700,  0.2088,  0.3697,  0.1819,  0.3546, -0.0446],\n",
      "        [-0.3591,  0.0244, -0.1649, -0.2495, -0.2890,  0.2452]],\n",
      "       requires_grad=True)\n",
      "loss: 103.974655  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2578,  0.1410, -0.0885, -0.1570, -0.1578, -0.1504],\n",
      "        [-0.2552, -0.2928,  0.1083,  0.1792, -0.2207,  0.0541],\n",
      "        [ 0.3550,  0.1834, -0.3723,  0.2434, -0.2119, -0.3729],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0700,  0.2088,  0.3697,  0.1818,  0.3546, -0.0446],\n",
      "        [-0.3591,  0.0244, -0.1649, -0.2496, -0.2890,  0.2452]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.188748 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 166.355316  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2578,  0.1410, -0.0885, -0.1571, -0.1578, -0.1504],\n",
      "        [-0.2552, -0.2928,  0.1083,  0.1793, -0.2207,  0.0541],\n",
      "        [ 0.3550,  0.1834, -0.3723,  0.2435, -0.2119, -0.3729],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0700,  0.2088,  0.3697,  0.1817,  0.3546, -0.0446],\n",
      "        [-0.3591,  0.0244, -0.1649, -0.2497, -0.2890,  0.2452]],\n",
      "       requires_grad=True)\n",
      "loss: 162.196930  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2578,  0.1410, -0.0885, -0.1571, -0.1578, -0.1504],\n",
      "        [-0.2552, -0.2928,  0.1083,  0.1793, -0.2207,  0.0541],\n",
      "        [ 0.3550,  0.1834, -0.3723,  0.2436, -0.2119, -0.3729],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0700,  0.2088,  0.3697,  0.1816,  0.3546, -0.0446],\n",
      "        [-0.3591,  0.0244, -0.1649, -0.2497, -0.2890,  0.2452]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.193258 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 128.926224  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2578,  0.1410, -0.0885, -0.1572, -0.1578, -0.1504],\n",
      "        [-0.2551, -0.2928,  0.1083,  0.1794, -0.2207,  0.0541],\n",
      "        [ 0.3550,  0.1834, -0.3723,  0.2437, -0.2119, -0.3729],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0700,  0.2088,  0.3697,  0.1816,  0.3546, -0.0446],\n",
      "        [-0.3591,  0.0244, -0.1649, -0.2498, -0.2890,  0.2451]],\n",
      "       requires_grad=True)\n",
      "loss: 158.036697  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2578,  0.1410, -0.0885, -0.1573, -0.1578, -0.1504],\n",
      "        [-0.2551, -0.2928,  0.1083,  0.1794, -0.2207,  0.0541],\n",
      "        [ 0.3550,  0.1834, -0.3723,  0.2438, -0.2119, -0.3729],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0700,  0.2088,  0.3697,  0.1815,  0.3546, -0.0446],\n",
      "        [-0.3591,  0.0244, -0.1649, -0.2499, -0.2890,  0.2451]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.195662 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 112.291748  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2578,  0.1410, -0.0885, -0.1573, -0.1578, -0.1504],\n",
      "        [-0.2551, -0.2928,  0.1083,  0.1795, -0.2207,  0.0541],\n",
      "        [ 0.3550,  0.1834, -0.3723,  0.2438, -0.2119, -0.3729],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0700,  0.2088,  0.3697,  0.1814,  0.3546, -0.0446],\n",
      "        [-0.3591,  0.0244, -0.1649, -0.2499, -0.2890,  0.2451]],\n",
      "       requires_grad=True)\n",
      "loss: 145.560883  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2578,  0.1410, -0.0885, -0.1574, -0.1578, -0.1504],\n",
      "        [-0.2551, -0.2928,  0.1083,  0.1795, -0.2207,  0.0542],\n",
      "        [ 0.3550,  0.1834, -0.3723,  0.2439, -0.2119, -0.3729],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0700,  0.2088,  0.3697,  0.1813,  0.3546, -0.0446],\n",
      "        [-0.3591,  0.0244, -0.1649, -0.2500, -0.2890,  0.2451]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.200205 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 145.562668  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2578,  0.1410, -0.0885, -0.1574, -0.1578, -0.1504],\n",
      "        [-0.2551, -0.2928,  0.1083,  0.1796, -0.2207,  0.0542],\n",
      "        [ 0.3550,  0.1834, -0.3723,  0.2440, -0.2119, -0.3729],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0699,  0.2088,  0.3697,  0.1813,  0.3546, -0.0447],\n",
      "        [-0.3591,  0.0244, -0.1649, -0.2500, -0.2890,  0.2451]],\n",
      "       requires_grad=True)\n",
      "loss: 128.925720  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2578,  0.1410, -0.0885, -0.1575, -0.1578, -0.1505],\n",
      "        [-0.2551, -0.2928,  0.1083,  0.1796, -0.2207,  0.0542],\n",
      "        [ 0.3551,  0.1834, -0.3723,  0.2441, -0.2119, -0.3728],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0699,  0.2088,  0.3697,  0.1812,  0.3546, -0.0447],\n",
      "        [-0.3591,  0.0244, -0.1649, -0.2501, -0.2890,  0.2451]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.191065 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 120.606567  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2578,  0.1410, -0.0885, -0.1575, -0.1578, -0.1505],\n",
      "        [-0.2551, -0.2928,  0.1083,  0.1797, -0.2207,  0.0542],\n",
      "        [ 0.3550,  0.1834, -0.3723,  0.2441, -0.2119, -0.3728],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0699,  0.2088,  0.3697,  0.1812,  0.3546, -0.0447],\n",
      "        [-0.3591,  0.0244, -0.1649, -0.2501, -0.2890,  0.2451]],\n",
      "       requires_grad=True)\n",
      "loss: 133.083939  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2579,  0.1410, -0.0885, -0.1576, -0.1578, -0.1505],\n",
      "        [-0.2551, -0.2928,  0.1083,  0.1797, -0.2207,  0.0542],\n",
      "        [ 0.3551,  0.1834, -0.3723,  0.2442, -0.2119, -0.3728],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0699,  0.2088,  0.3697,  0.1811,  0.3546, -0.0447],\n",
      "        [-0.3592,  0.0244, -0.1649, -0.2502, -0.2890,  0.2451]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.193325 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 135.166946  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2579,  0.1410, -0.0885, -0.1576, -0.1578, -0.1505],\n",
      "        [-0.2551, -0.2928,  0.1083,  0.1798, -0.2207,  0.0542],\n",
      "        [ 0.3551,  0.1834, -0.3723,  0.2443, -0.2119, -0.3728],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0699,  0.2088,  0.3697,  0.1810,  0.3546, -0.0447],\n",
      "        [-0.3592,  0.0244, -0.1648, -0.2502, -0.2890,  0.2451]],\n",
      "       requires_grad=True)\n",
      "loss: 112.289825  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2579,  0.1410, -0.0885, -0.1577, -0.1578, -0.1505],\n",
      "        [-0.2551, -0.2928,  0.1083,  0.1799, -0.2207,  0.0542],\n",
      "        [ 0.3551,  0.1834, -0.3723,  0.2444, -0.2119, -0.3728],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0699,  0.2088,  0.3697,  0.1809,  0.3546, -0.0447],\n",
      "        [-0.3592,  0.0244, -0.1648, -0.2503, -0.2890,  0.2451]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.197891 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 116.448845  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2579,  0.1410, -0.0885, -0.1577, -0.1578, -0.1505],\n",
      "        [-0.2551, -0.2928,  0.1083,  0.1799, -0.2207,  0.0542],\n",
      "        [ 0.3551,  0.1834, -0.3724,  0.2445, -0.2119, -0.3728],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0699,  0.2088,  0.3697,  0.1809,  0.3546, -0.0447],\n",
      "        [-0.3592,  0.0244, -0.1648, -0.2504, -0.2890,  0.2451]],\n",
      "       requires_grad=True)\n",
      "loss: 106.051033  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2579,  0.1410, -0.0885, -0.1578, -0.1578, -0.1505],\n",
      "        [-0.2551, -0.2928,  0.1083,  0.1799, -0.2207,  0.0542],\n",
      "        [ 0.3551,  0.1834, -0.3724,  0.2446, -0.2119, -0.3728],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0699,  0.2088,  0.3697,  0.1808,  0.3546, -0.0447],\n",
      "        [-0.3592,  0.0244, -0.1648, -0.2504, -0.2890,  0.2450]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.200208 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 153.875671  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2579,  0.1410, -0.0885, -0.1579, -0.1578, -0.1505],\n",
      "        [-0.2551, -0.2928,  0.1083,  0.1800, -0.2207,  0.0542],\n",
      "        [ 0.3551,  0.1834, -0.3724,  0.2446, -0.2119, -0.3728],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0699,  0.2088,  0.3697,  0.1807,  0.3546, -0.0447],\n",
      "        [-0.3592,  0.0244, -0.1648, -0.2505, -0.2890,  0.2450]],\n",
      "       requires_grad=True)\n",
      "loss: 124.765930  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2579,  0.1410, -0.0885, -0.1579, -0.1578, -0.1505],\n",
      "        [-0.2551, -0.2928,  0.1083,  0.1800, -0.2207,  0.0542],\n",
      "        [ 0.3551,  0.1834, -0.3724,  0.2447, -0.2119, -0.3727],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0699,  0.2088,  0.3697,  0.1806,  0.3546, -0.0448],\n",
      "        [-0.3592,  0.0244, -0.1648, -0.2505, -0.2890,  0.2450]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.190999 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 137.223755  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2579,  0.1410, -0.0885, -0.1580, -0.1578, -0.1505],\n",
      "        [-0.2551, -0.2928,  0.1083,  0.1801, -0.2207,  0.0542],\n",
      "        [ 0.3551,  0.1834, -0.3724,  0.2448, -0.2119, -0.3727],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0699,  0.2088,  0.3697,  0.1806,  0.3546, -0.0448],\n",
      "        [-0.3592,  0.0244, -0.1648, -0.2506, -0.2891,  0.2450]],\n",
      "       requires_grad=True)\n",
      "loss: 145.560898  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2579,  0.1410, -0.0885, -0.1580, -0.1578, -0.1505],\n",
      "        [-0.2551, -0.2928,  0.1083,  0.1801, -0.2207,  0.0542],\n",
      "        [ 0.3551,  0.1834, -0.3724,  0.2449, -0.2119, -0.3727],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0699,  0.2088,  0.3697,  0.1805,  0.3546, -0.0448],\n",
      "        [-0.3592,  0.0244, -0.1648, -0.2506, -0.2891,  0.2450]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.187590 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 120.606491  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2579,  0.1410, -0.0885, -0.1581, -0.1578, -0.1505],\n",
      "        [-0.2550, -0.2928,  0.1083,  0.1802, -0.2207,  0.0542],\n",
      "        [ 0.3551,  0.1834, -0.3724,  0.2449, -0.2119, -0.3727],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0698,  0.2088,  0.3697,  0.1805,  0.3546, -0.0448],\n",
      "        [-0.3592,  0.0244, -0.1648, -0.2507, -0.2891,  0.2450]],\n",
      "       requires_grad=True)\n",
      "loss: 128.932785  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2579,  0.1410, -0.0885, -0.1581, -0.1578, -0.1506],\n",
      "        [-0.2550, -0.2928,  0.1083,  0.1802, -0.2207,  0.0543],\n",
      "        [ 0.3552,  0.1834, -0.3724,  0.2450, -0.2118, -0.3727],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0698,  0.2088,  0.3697,  0.1804,  0.3546, -0.0448],\n",
      "        [-0.3592,  0.0244, -0.1648, -0.2507, -0.2891,  0.2450]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.193343 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 141.402054  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2579,  0.1410, -0.0885, -0.1582, -0.1578, -0.1506],\n",
      "        [-0.2550, -0.2928,  0.1083,  0.1803, -0.2207,  0.0543],\n",
      "        [ 0.3552,  0.1834, -0.3724,  0.2451, -0.2118, -0.3727],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0826,  0.0932,  0.0332],\n",
      "        [ 0.0698,  0.2088,  0.3697,  0.1803,  0.3545, -0.0448],\n",
      "        [-0.3592,  0.0244, -0.1648, -0.2508, -0.2891,  0.2450]],\n",
      "       requires_grad=True)\n",
      "loss: 162.217499  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2579,  0.1410, -0.0885, -0.1582, -0.1578, -0.1506],\n",
      "        [-0.2550, -0.2928,  0.1083,  0.1803, -0.2206,  0.0543],\n",
      "        [ 0.3552,  0.1834, -0.3724,  0.2452, -0.2118, -0.3727],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0698,  0.2088,  0.3697,  0.1803,  0.3545, -0.0448],\n",
      "        [-0.3592,  0.0244, -0.1648, -0.2509, -0.2891,  0.2450]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.191016 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 147.639404  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2579,  0.1410, -0.0885, -0.1583, -0.1578, -0.1506],\n",
      "        [-0.2550, -0.2928,  0.1083,  0.1804, -0.2206,  0.0543],\n",
      "        [ 0.3552,  0.1834, -0.3724,  0.2452, -0.2118, -0.3727],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0698,  0.2088,  0.3697,  0.1802,  0.3545, -0.0448],\n",
      "        [-0.3592,  0.0244, -0.1648, -0.2509, -0.2891,  0.2450]],\n",
      "       requires_grad=True)\n",
      "loss: 128.930084  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1583, -0.1578, -0.1506],\n",
      "        [-0.2550, -0.2928,  0.1083,  0.1804, -0.2206,  0.0543],\n",
      "        [ 0.3552,  0.1834, -0.3724,  0.2453, -0.2118, -0.3726],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0698,  0.2088,  0.3697,  0.1801,  0.3545, -0.0448],\n",
      "        [-0.3593,  0.0244, -0.1648, -0.2510, -0.2891,  0.2450]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.190962 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 128.929489  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1584, -0.1579, -0.1506],\n",
      "        [-0.2550, -0.2928,  0.1083,  0.1804, -0.2206,  0.0543],\n",
      "        [ 0.3552,  0.1834, -0.3724,  0.2454, -0.2118, -0.3726],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0698,  0.2088,  0.3697,  0.1801,  0.3545, -0.0448],\n",
      "        [-0.3593,  0.0244, -0.1648, -0.2510, -0.2891,  0.2449]],\n",
      "       requires_grad=True)\n",
      "loss: 128.949265  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1585, -0.1579, -0.1506],\n",
      "        [-0.2550, -0.2928,  0.1083,  0.1805, -0.2206,  0.0543],\n",
      "        [ 0.3552,  0.1834, -0.3724,  0.2455, -0.2118, -0.3726],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0698,  0.2088,  0.3697,  0.1800,  0.3545, -0.0449],\n",
      "        [-0.3593,  0.0244, -0.1648, -0.2511, -0.2891,  0.2449]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.195521 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 112.294830  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1585, -0.1579, -0.1506],\n",
      "        [-0.2550, -0.2928,  0.1083,  0.1805, -0.2206,  0.0543],\n",
      "        [ 0.3552,  0.1834, -0.3724,  0.2455, -0.2118, -0.3726],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0698,  0.2088,  0.3697,  0.1799,  0.3545, -0.0449],\n",
      "        [-0.3593,  0.0244, -0.1648, -0.2511, -0.2891,  0.2449]],\n",
      "       requires_grad=True)\n",
      "loss: 108.132416  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1586, -0.1579, -0.1506],\n",
      "        [-0.2550, -0.2928,  0.1083,  0.1806, -0.2206,  0.0543],\n",
      "        [ 0.3553,  0.1834, -0.3724,  0.2456, -0.2118, -0.3726],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0697,  0.2088,  0.3697,  0.1798,  0.3545, -0.0449],\n",
      "        [-0.3593,  0.0244, -0.1648, -0.2512, -0.2891,  0.2449]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.190930 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: 83.178131  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1586, -0.1579, -0.1506],\n",
      "        [-0.2550, -0.2928,  0.1083,  0.1806, -0.2206,  0.0543],\n",
      "        [ 0.3552,  0.1834, -0.3724,  0.2457, -0.2118, -0.3726],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0698,  0.2088,  0.3697,  0.1798,  0.3545, -0.0449],\n",
      "        [-0.3593,  0.0244, -0.1648, -0.2512, -0.2891,  0.2449]],\n",
      "       requires_grad=True)\n",
      "loss: 120.606911  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1587, -0.1579, -0.1506],\n",
      "        [-0.2550, -0.2928,  0.1083,  0.1807, -0.2206,  0.0543],\n",
      "        [ 0.3553,  0.1834, -0.3724,  0.2458, -0.2118, -0.3726],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0698,  0.2088,  0.3697,  0.1797,  0.3545, -0.0449],\n",
      "        [-0.3593,  0.0244, -0.1648, -0.2513, -0.2891,  0.2449]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.193287 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: 103.972694  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1587, -0.1579, -0.1506],\n",
      "        [-0.2550, -0.2928,  0.1083,  0.1807, -0.2206,  0.0543],\n",
      "        [ 0.3553,  0.1834, -0.3724,  0.2458, -0.2118, -0.3726],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0697,  0.2088,  0.3697,  0.1797,  0.3545, -0.0449],\n",
      "        [-0.3593,  0.0244, -0.1648, -0.2513, -0.2891,  0.2449]],\n",
      "       requires_grad=True)\n",
      "loss: 149.719772  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1588, -0.1579, -0.1507],\n",
      "        [-0.2550, -0.2928,  0.1083,  0.1808, -0.2206,  0.0544],\n",
      "        [ 0.3553,  0.1834, -0.3724,  0.2459, -0.2118, -0.3725],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0697,  0.2088,  0.3697,  0.1796,  0.3545, -0.0449],\n",
      "        [-0.3593,  0.0244, -0.1648, -0.2514, -0.2891,  0.2449]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.193253 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: 153.878769  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1588, -0.1579, -0.1507],\n",
      "        [-0.2550, -0.2928,  0.1083,  0.1808, -0.2206,  0.0544],\n",
      "        [ 0.3553,  0.1834, -0.3724,  0.2460, -0.2118, -0.3725],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0697,  0.2088,  0.3697,  0.1796,  0.3545, -0.0449],\n",
      "        [-0.3593,  0.0244, -0.1648, -0.2514, -0.2891,  0.2449]],\n",
      "       requires_grad=True)\n",
      "loss: 133.063354  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1588, -0.1579, -0.1507],\n",
      "        [-0.2550, -0.2928,  0.1083,  0.1809, -0.2206,  0.0544],\n",
      "        [ 0.3553,  0.1834, -0.3724,  0.2461, -0.2118, -0.3725],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0697,  0.2088,  0.3697,  0.1795,  0.3545, -0.0449],\n",
      "        [-0.3593,  0.0244, -0.1648, -0.2515, -0.2891,  0.2449]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.200056 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: 149.746460  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1589, -0.1579, -0.1507],\n",
      "        [-0.2549, -0.2928,  0.1083,  0.1809, -0.2206,  0.0544],\n",
      "        [ 0.3553,  0.1834, -0.3724,  0.2461, -0.2118, -0.3725],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0697,  0.2088,  0.3697,  0.1794,  0.3545, -0.0449],\n",
      "        [-0.3593,  0.0244, -0.1648, -0.2516, -0.2891,  0.2449]],\n",
      "       requires_grad=True)\n",
      "loss: 122.686905  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1590, -0.1579, -0.1507],\n",
      "        [-0.2549, -0.2928,  0.1083,  0.1810, -0.2206,  0.0544],\n",
      "        [ 0.3553,  0.1834, -0.3724,  0.2462, -0.2118, -0.3725],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0697,  0.2088,  0.3697,  0.1793,  0.3545, -0.0450],\n",
      "        [-0.3593,  0.0244, -0.1648, -0.2516, -0.2891,  0.2449]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.190988 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: 145.550430  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1590, -0.1579, -0.1507],\n",
      "        [-0.2549, -0.2928,  0.1083,  0.1810, -0.2206,  0.0544],\n",
      "        [ 0.3553,  0.1834, -0.3724,  0.2463, -0.2118, -0.3725],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0697,  0.2088,  0.3697,  0.1793,  0.3545, -0.0450],\n",
      "        [-0.3593,  0.0244, -0.1648, -0.2516, -0.2891,  0.2448]],\n",
      "       requires_grad=True)\n",
      "loss: 149.712082  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1590, -0.1579, -0.1507],\n",
      "        [-0.2549, -0.2928,  0.1083,  0.1811, -0.2206,  0.0544],\n",
      "        [ 0.3553,  0.1834, -0.3724,  0.2463, -0.2118, -0.3725],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0697,  0.2088,  0.3697,  0.1792,  0.3545, -0.0450],\n",
      "        [-0.3593,  0.0244, -0.1648, -0.2517, -0.2891,  0.2448]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.197748 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: 158.037781  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1591, -0.1579, -0.1507],\n",
      "        [-0.2549, -0.2928,  0.1083,  0.1811, -0.2206,  0.0544],\n",
      "        [ 0.3553,  0.1834, -0.3724,  0.2464, -0.2118, -0.3725],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0697,  0.2088,  0.3697,  0.1792,  0.3545, -0.0450],\n",
      "        [-0.3594,  0.0244, -0.1648, -0.2517, -0.2891,  0.2448]],\n",
      "       requires_grad=True)\n",
      "loss: 133.084702  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2580,  0.1410, -0.0885, -0.1591, -0.1579, -0.1507],\n",
      "        [-0.2549, -0.2928,  0.1083,  0.1812, -0.2206,  0.0544],\n",
      "        [ 0.3553,  0.1834, -0.3724,  0.2465, -0.2117, -0.3725],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0697,  0.2088,  0.3697,  0.1791,  0.3545, -0.0450],\n",
      "        [-0.3594,  0.0244, -0.1648, -0.2518, -0.2891,  0.2448]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.195472 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: 147.643814  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2581,  0.1410, -0.0885, -0.1592, -0.1579, -0.1507],\n",
      "        [-0.2549, -0.2928,  0.1083,  0.1812, -0.2206,  0.0544],\n",
      "        [ 0.3554,  0.1834, -0.3724,  0.2465, -0.2117, -0.3725],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0697,  0.2088,  0.3697,  0.1791,  0.3545, -0.0450],\n",
      "        [-0.3594,  0.0244, -0.1648, -0.2519, -0.2891,  0.2448]],\n",
      "       requires_grad=True)\n",
      "loss: 128.925400  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2581,  0.1410, -0.0885, -0.1593, -0.1579, -0.1507],\n",
      "        [-0.2549, -0.2928,  0.1083,  0.1813, -0.2206,  0.0544],\n",
      "        [ 0.3554,  0.1834, -0.3724,  0.2467, -0.2117, -0.3724],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0696,  0.2088,  0.3697,  0.1790,  0.3545, -0.0450],\n",
      "        [-0.3594,  0.0244, -0.1648, -0.2519, -0.2891,  0.2448]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.197791 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: 149.719788  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2581,  0.1410, -0.0885, -0.1593, -0.1579, -0.1507],\n",
      "        [-0.2549, -0.2928,  0.1083,  0.1813, -0.2206,  0.0544],\n",
      "        [ 0.3554,  0.1834, -0.3724,  0.2467, -0.2117, -0.3724],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0696,  0.2088,  0.3697,  0.1789,  0.3545, -0.0450],\n",
      "        [-0.3594,  0.0244, -0.1648, -0.2520, -0.2891,  0.2448]],\n",
      "       requires_grad=True)\n",
      "loss: 116.448257  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2581,  0.1410, -0.0885, -0.1594, -0.1579, -0.1508],\n",
      "        [-0.2549, -0.2928,  0.1083,  0.1813, -0.2206,  0.0544],\n",
      "        [ 0.3554,  0.1834, -0.3724,  0.2468, -0.2117, -0.3724],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0696,  0.2088,  0.3697,  0.1788,  0.3545, -0.0450],\n",
      "        [-0.3594,  0.0244, -0.1648, -0.2520, -0.2891,  0.2448]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.190962 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: 116.451401  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2581,  0.1410, -0.0885, -0.1594, -0.1579, -0.1508],\n",
      "        [-0.2549, -0.2928,  0.1083,  0.1814, -0.2206,  0.0544],\n",
      "        [ 0.3554,  0.1834, -0.3724,  0.2468, -0.2117, -0.3724],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0696,  0.2088,  0.3697,  0.1788,  0.3544, -0.0450],\n",
      "        [-0.3594,  0.0244, -0.1648, -0.2521, -0.2891,  0.2448]],\n",
      "       requires_grad=True)\n",
      "loss: 112.290489  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2581,  0.1410, -0.0885, -0.1595, -0.1579, -0.1508],\n",
      "        [-0.2549, -0.2928,  0.1083,  0.1814, -0.2206,  0.0545],\n",
      "        [ 0.3554,  0.1834, -0.3724,  0.2469, -0.2117, -0.3724],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0696,  0.2088,  0.3697,  0.1787,  0.3544, -0.0451],\n",
      "        [-0.3594,  0.0244, -0.1648, -0.2521, -0.2892,  0.2448]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.194448 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: 151.800064  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2581,  0.1410, -0.0885, -0.1595, -0.1579, -0.1508],\n",
      "        [-0.2549, -0.2928,  0.1083,  0.1815, -0.2206,  0.0545],\n",
      "        [ 0.3554,  0.1834, -0.3724,  0.2470, -0.2117, -0.3724],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0696,  0.2088,  0.3697,  0.1787,  0.3544, -0.0451],\n",
      "        [-0.3594,  0.0244, -0.1648, -0.2522, -0.2892,  0.2448]],\n",
      "       requires_grad=True)\n",
      "loss: 128.925323  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2581,  0.1410, -0.0885, -0.1595, -0.1579, -0.1508],\n",
      "        [-0.2549, -0.2928,  0.1083,  0.1815, -0.2206,  0.0545],\n",
      "        [ 0.3554,  0.1834, -0.3724,  0.2470, -0.2117, -0.3724],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0696,  0.2088,  0.3697,  0.1786,  0.3544, -0.0451],\n",
      "        [-0.3594,  0.0244, -0.1648, -0.2522, -0.2892,  0.2448]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.188673 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: 133.094193  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2581,  0.1410, -0.0885, -0.1596, -0.1579, -0.1508],\n",
      "        [-0.2549, -0.2928,  0.1083,  0.1816, -0.2206,  0.0545],\n",
      "        [ 0.3554,  0.1834, -0.3724,  0.2471, -0.2117, -0.3724],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0696,  0.2088,  0.3697,  0.1786,  0.3544, -0.0451],\n",
      "        [-0.3594,  0.0244, -0.1648, -0.2523, -0.2892,  0.2447]],\n",
      "       requires_grad=True)\n",
      "loss: 120.610558  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2581,  0.1410, -0.0885, -0.1597, -0.1579, -0.1508],\n",
      "        [-0.2548, -0.2928,  0.1083,  0.1816, -0.2206,  0.0545],\n",
      "        [ 0.3555,  0.1834, -0.3724,  0.2472, -0.2117, -0.3723],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0696,  0.2088,  0.3698,  0.1785,  0.3544, -0.0451],\n",
      "        [-0.3594,  0.0244, -0.1648, -0.2523, -0.2892,  0.2447]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.200037 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: 149.719818  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2581,  0.1410, -0.0885, -0.1597, -0.1579, -0.1508],\n",
      "        [-0.2549, -0.2928,  0.1083,  0.1816, -0.2206,  0.0545],\n",
      "        [ 0.3555,  0.1834, -0.3724,  0.2473, -0.2117, -0.3723],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0696,  0.2088,  0.3698,  0.1784,  0.3544, -0.0451],\n",
      "        [-0.3594,  0.0244, -0.1648, -0.2524, -0.2892,  0.2447]],\n",
      "       requires_grad=True)\n",
      "loss: 153.881104  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2581,  0.1410, -0.0885, -0.1598, -0.1579, -0.1508],\n",
      "        [-0.2548, -0.2928,  0.1083,  0.1817, -0.2206,  0.0545],\n",
      "        [ 0.3555,  0.1834, -0.3724,  0.2474, -0.2117, -0.3723],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0696,  0.2088,  0.3698,  0.1784,  0.3544, -0.0451],\n",
      "        [-0.3594,  0.0244, -0.1648, -0.2524, -0.2892,  0.2447]],\n",
      "       requires_grad=True)\n",
      "Test Error: \n",
      " Accuracy: 50.2%, Avg loss: 133.190889 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: 137.242508  [   64/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2581,  0.1410, -0.0885, -0.1598, -0.1579, -0.1508],\n",
      "        [-0.2548, -0.2928,  0.1083,  0.1817, -0.2206,  0.0545],\n",
      "        [ 0.3555,  0.1834, -0.3724,  0.2474, -0.2117, -0.3723],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0696,  0.2088,  0.3698,  0.1783,  0.3544, -0.0451],\n",
      "        [-0.3594,  0.0244, -0.1648, -0.2525, -0.2892,  0.2447]],\n",
      "       requires_grad=True)\n",
      "loss: 112.290375  [ 6464/ 9285]\n",
      "Parameter containing:\n",
      "tensor([[-0.2582,  0.1410, -0.0885, -0.1598, -0.1579, -0.1508],\n",
      "        [-0.2548, -0.2928,  0.1083,  0.1818, -0.2205,  0.0545],\n",
      "        [ 0.3555,  0.1834, -0.3724,  0.2475, -0.2117, -0.3723],\n",
      "        [-0.0099,  0.2792,  0.0778,  0.0825,  0.0932,  0.0332],\n",
      "        [ 0.0695,  0.2088,  0.3698,  0.1782,  0.3544, -0.0451],\n",
      "        [-0.3595,  0.0244, -0.1648, -0.2525, -0.2892,  0.2447]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[207], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m     train(s17_train_loader, model, loss_fn, optimizer)\n\u001b[1;32m----> 5\u001b[0m     \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms17_test_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[204], line 33\u001b[0m, in \u001b[0;36mtest\u001b[1;34m(dataloader, model, loss_fn)\u001b[0m\n\u001b[0;32m     31\u001b[0m test_loss, correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bmost\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\bmost\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\bmost\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bmost\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bmost\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\bmost\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\bmost\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(s17_train_loader, model, loss_fn, optimizer)\n",
    "    test(s17_test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0790e+03, 7.5533e-01, 2.0790e+00, 3.1700e+02, 5.2050e-01, 1.2384e+00]),\n",
       " 1)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s17_dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'9ce942df8dc4fff74c13d9490b25e77f98074ebe9841896c'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 'https://data.ninjakiwi.com/battles2/users/9ce942df8dc4fff74c13d9490b25e77f98074ebe9841896c'\n",
    "user_id[42:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Dataset For Matches\n",
    "\n",
    "Let's create a dataset with the columns organized as follows:\n",
    "- Map\n",
    "- Left Hero\n",
    "- Left Tower 1\n",
    "- Left Tower 2\n",
    "- Left Tower 3\n",
    "- Right Hero\n",
    "- Right Tower 1\n",
    "- Right Tower 2\n",
    "- Right Tower 3\n",
    "- Winner (0 if left player wins, 1 if right player wins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = random_split(ld.data, [0.8,0.2])\n",
    "data_train = split[0]\n",
    "data_test = split[1]\n",
    "\n",
    "class S17(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        body = self.data[idx]['body']\n",
    "    \n",
    "        # Map\n",
    "        match_map = ld.map_encoding[body['map']]\n",
    "\n",
    "        # Left player's picks\n",
    "        left_hero = ld.hero_encoding[body['playerLeft']['hero']]\n",
    "        left_t1 = ld.tower_encoding[body['playerLeft']['towerone']]\n",
    "        left_t2 = ld.tower_encoding[body['playerLeft']['towertwo']]\n",
    "        left_t3 = ld.tower_encoding[body['playerLeft']['towerthree']]\n",
    "\n",
    "        # Right player's picks\n",
    "        right_hero = ld.hero_encoding[body['playerRight']['hero']]\n",
    "        right_t1 = ld.tower_encoding[body['playerRight']['towerone']]\n",
    "        right_t2 = ld.tower_encoding[body['playerRight']['towertwo']]\n",
    "        right_t3 = ld.tower_encoding[body['playerRight']['towerthree']]\n",
    "\n",
    "        # Who won?\n",
    "        if body['playerRight']['result'] == 'win':\n",
    "            winner = 1\n",
    "        elif body['playerRight']['result'] == 'lose':\n",
    "            winner = 0\n",
    "        else:\n",
    "            winner = 0.5\n",
    "\n",
    "        return torch.tensor([match_map, left_hero, left_t1, left_t2, left_t3, right_hero, right_t1, right_t2, right_t3]), winner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration\n",
    "\n",
    "Here, I print a few data points to show what the data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([10, 10,  0, 18, 20,  6,  0, 20,  7]), 1)\n",
      "(tensor([ 7,  6,  0,  7, 20, 17,  9, 20, 21]), 0)\n",
      "(tensor([ 5, 18,  7,  5,  3,  2, 17,  6, 20]), 1)\n",
      "(tensor([ 1,  7, 21,  9, 18, 10,  6, 14,  4]), 0)\n",
      "(tensor([ 0,  0,  1, 13, 20, 16,  2,  1,  7]), 0)\n",
      "(tensor([15, 10, 18,  1,  7,  1,  7, 16, 20]), 1)\n",
      "(tensor([15,  8, 13, 20, 12, 15,  6,  5, 17]), 0)\n",
      "(tensor([11,  0,  3, 10, 18,  0, 20, 10,  1]), 1)\n",
      "(tensor([ 6,  5, 11, 10,  2,  5,  2, 10, 11]), 1)\n",
      "(tensor([19,  8, 15,  8, 19,  2, 17, 14,  4]), 0)\n"
     ]
    }
   ],
   "source": [
    "s17_train = S17(data_train)\n",
    "s17_test = S17(data_test)\n",
    "\n",
    "for i in range(10):\n",
    "    print(s17_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, W]: torch.Size([64, 9])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "\n",
    "# Create data loaders.\n",
    "s17_train_loader = DataLoader(s17_train, batch_size=batch_size)\n",
    "s17_test_loader = DataLoader(s17_test, batch_size=batch_size)\n",
    "\n",
    "for X, y in s17_test_loader:\n",
    "    print(f\"Shape of X [N, W]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction\n",
    "\n",
    "To begin, let's use CUDA to speed up the training a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "device= \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the model by subclassing with nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (tower_embedding): Sequential(\n",
      "    (0): Embedding(22, 3)\n",
      "  )\n",
      "  (hero_embedding): Sequential(\n",
      "    (0): Embedding(20, 3)\n",
      "  )\n",
      "  (map_embedding): Sequential(\n",
      "    (0): Embedding(21, 3)\n",
      "  )\n",
      "  (linear_sigm): Sequential(\n",
      "    (0): Linear(in_features=15, out_features=1, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, dim = 3):\n",
    "        super().__init__()\n",
    "        self.tower_embedding = nn.Sequential(nn.Embedding(22, dim))\n",
    "        self.hero_embedding = nn.Sequential(nn.Embedding(20, dim))\n",
    "        self.map_embedding = nn.Sequential(nn.Embedding(21, dim))\n",
    "\n",
    "        self.linear_sigm = nn.Sequential(nn.Linear(5*dim, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply the embedding to the match location \n",
    "        # print(x[0])\n",
    "        map_vec = self.map_embedding(x[:,0])\n",
    "\n",
    "        left_hero_vec = self.hero_embedding(x[:,1])\n",
    "        left_comp_vec = self.tower_embedding(x[:,2]) + self.tower_embedding(x[:,3]) + self.tower_embedding(x[:,4])\n",
    "\n",
    "        right_hero_vec = self.hero_embedding(x[:,5])\n",
    "        right_comp_vec = self.tower_embedding(x[:,6]) + self.tower_embedding(x[:,7]) + self.tower_embedding(x[:,8])\n",
    "\n",
    "        # Concatenate the vectors all together nice and neatly!\n",
    "        embedding_vec = torch.cat((map_vec, left_hero_vec, left_comp_vec, right_hero_vec, right_comp_vec),1)\n",
    "\n",
    "        # Now, pass the embedding vector through a linear layer\n",
    "        y = self.linear_sigm(embedding_vec)\n",
    "        # print(y[0])\n",
    "        return torch.flatten(y)\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the loss function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y.long())\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y.long()).item()\n",
    "            # print(torch.abs(torch.round(y - pred)))\n",
    "            # print(torch.tensor([1 for i in range(batch_size)]))\n",
    "            # print(torch.tensor([1 for i in range(y.size()[0])]) - torch.abs(torch.round(y - pred)))\n",
    "            correct += torch.sum(torch.tensor([1 for i in range(y.size()[0])]) - torch.abs(torch.round(y - pred)))\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: -0.999989  [   64/37138]\n",
      "loss: -0.999985  [ 6464/37138]\n",
      "loss: -0.999966  [12864/37138]\n",
      "loss: -0.999999  [19264/37138]\n",
      "loss: -0.999997  [25664/37138]\n",
      "loss: -0.999997  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999350 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: -0.999991  [   64/37138]\n",
      "loss: -0.999987  [ 6464/37138]\n",
      "loss: -0.999971  [12864/37138]\n",
      "loss: -0.999999  [19264/37138]\n",
      "loss: -0.999998  [25664/37138]\n",
      "loss: -0.999997  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999429 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: -0.999993  [   64/37138]\n",
      "loss: -0.999989  [ 6464/37138]\n",
      "loss: -0.999974  [12864/37138]\n",
      "loss: -0.999999  [19264/37138]\n",
      "loss: -0.999998  [25664/37138]\n",
      "loss: -0.999998  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999491 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: -0.999994  [   64/37138]\n",
      "loss: -0.999991  [ 6464/37138]\n",
      "loss: -0.999977  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -0.999999  [25664/37138]\n",
      "loss: -0.999998  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999540 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: -0.999995  [   64/37138]\n",
      "loss: -0.999992  [ 6464/37138]\n",
      "loss: -0.999980  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -0.999999  [25664/37138]\n",
      "loss: -0.999998  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999581 \n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: -0.999995  [   64/37138]\n",
      "loss: -0.999993  [ 6464/37138]\n",
      "loss: -0.999982  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -0.999999  [25664/37138]\n",
      "loss: -0.999999  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999615 \n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: -0.999996  [   64/37138]\n",
      "loss: -0.999993  [ 6464/37138]\n",
      "loss: -0.999983  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -0.999999  [25664/37138]\n",
      "loss: -0.999999  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999644 \n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: -0.999996  [   64/37138]\n",
      "loss: -0.999994  [ 6464/37138]\n",
      "loss: -0.999985  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -0.999999  [25664/37138]\n",
      "loss: -0.999999  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999669 \n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: -0.999997  [   64/37138]\n",
      "loss: -0.999995  [ 6464/37138]\n",
      "loss: -0.999986  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -0.999999  [25664/37138]\n",
      "loss: -0.999999  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999691 \n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: -0.999997  [   64/37138]\n",
      "loss: -0.999995  [ 6464/37138]\n",
      "loss: -0.999987  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -0.999999  [25664/37138]\n",
      "loss: -0.999999  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999710 \n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: -0.999997  [   64/37138]\n",
      "loss: -0.999995  [ 6464/37138]\n",
      "loss: -0.999988  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -0.999999  [25664/37138]\n",
      "loss: -0.999999  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999727 \n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: -0.999998  [   64/37138]\n",
      "loss: -0.999996  [ 6464/37138]\n",
      "loss: -0.999989  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -0.999999  [25664/37138]\n",
      "loss: -0.999999  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999742 \n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: -0.999998  [   64/37138]\n",
      "loss: -0.999996  [ 6464/37138]\n",
      "loss: -0.999989  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -0.999999  [25664/37138]\n",
      "loss: -0.999999  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999755 \n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: -0.999998  [   64/37138]\n",
      "loss: -0.999996  [ 6464/37138]\n",
      "loss: -0.999990  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -0.999999  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999767 \n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: -0.999998  [   64/37138]\n",
      "loss: -0.999997  [ 6464/37138]\n",
      "loss: -0.999991  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -0.999999  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999778 \n",
      "\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: -0.999998  [   64/37138]\n",
      "loss: -0.999997  [ 6464/37138]\n",
      "loss: -0.999991  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -0.999999  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999788 \n",
      "\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: -0.999998  [   64/37138]\n",
      "loss: -0.999997  [ 6464/37138]\n",
      "loss: -0.999992  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -0.999999  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999797 \n",
      "\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: -0.999998  [   64/37138]\n",
      "loss: -0.999997  [ 6464/37138]\n",
      "loss: -0.999992  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999805 \n",
      "\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999997  [ 6464/37138]\n",
      "loss: -0.999992  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999813 \n",
      "\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999997  [ 6464/37138]\n",
      "loss: -0.999993  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999820 \n",
      "\n",
      "Epoch 21\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999997  [ 6464/37138]\n",
      "loss: -0.999993  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999826 \n",
      "\n",
      "Epoch 22\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999998  [ 6464/37138]\n",
      "loss: -0.999993  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999832 \n",
      "\n",
      "Epoch 23\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999998  [ 6464/37138]\n",
      "loss: -0.999994  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999838 \n",
      "\n",
      "Epoch 24\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999998  [ 6464/37138]\n",
      "loss: -0.999994  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999843 \n",
      "\n",
      "Epoch 25\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999998  [ 6464/37138]\n",
      "loss: -0.999994  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999848 \n",
      "\n",
      "Epoch 26\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999998  [ 6464/37138]\n",
      "loss: -0.999994  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999853 \n",
      "\n",
      "Epoch 27\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999998  [ 6464/37138]\n",
      "loss: -0.999995  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999857 \n",
      "\n",
      "Epoch 28\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999998  [ 6464/37138]\n",
      "loss: -0.999995  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999861 \n",
      "\n",
      "Epoch 29\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999998  [ 6464/37138]\n",
      "loss: -0.999995  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999865 \n",
      "\n",
      "Epoch 30\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999998  [ 6464/37138]\n",
      "loss: -0.999995  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999869 \n",
      "\n",
      "Epoch 31\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999998  [ 6464/37138]\n",
      "loss: -0.999995  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999872 \n",
      "\n",
      "Epoch 32\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999998  [ 6464/37138]\n",
      "loss: -0.999995  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999876 \n",
      "\n",
      "Epoch 33\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999998  [ 6464/37138]\n",
      "loss: -0.999995  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999879 \n",
      "\n",
      "Epoch 34\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999996  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999882 \n",
      "\n",
      "Epoch 35\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999996  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999884 \n",
      "\n",
      "Epoch 36\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999996  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999887 \n",
      "\n",
      "Epoch 37\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999996  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999890 \n",
      "\n",
      "Epoch 38\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999996  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999892 \n",
      "\n",
      "Epoch 39\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999996  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999894 \n",
      "\n",
      "Epoch 40\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999996  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999897 \n",
      "\n",
      "Epoch 41\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999996  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999899 \n",
      "\n",
      "Epoch 42\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999996  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999901 \n",
      "\n",
      "Epoch 43\n",
      "-------------------------------\n",
      "loss: -0.999999  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999903 \n",
      "\n",
      "Epoch 44\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999905 \n",
      "\n",
      "Epoch 45\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999906 \n",
      "\n",
      "Epoch 46\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999908 \n",
      "\n",
      "Epoch 47\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999910 \n",
      "\n",
      "Epoch 48\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999911 \n",
      "\n",
      "Epoch 49\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999913 \n",
      "\n",
      "Epoch 50\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999914 \n",
      "\n",
      "Epoch 51\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999916 \n",
      "\n",
      "Epoch 52\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999917 \n",
      "\n",
      "Epoch 53\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999919 \n",
      "\n",
      "Epoch 54\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999920 \n",
      "\n",
      "Epoch 55\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999921 \n",
      "\n",
      "Epoch 56\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999922 \n",
      "\n",
      "Epoch 57\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999924 \n",
      "\n",
      "Epoch 58\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999925 \n",
      "\n",
      "Epoch 59\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999926 \n",
      "\n",
      "Epoch 60\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999997  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999927 \n",
      "\n",
      "Epoch 61\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999928 \n",
      "\n",
      "Epoch 62\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999929 \n",
      "\n",
      "Epoch 63\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999930 \n",
      "\n",
      "Epoch 64\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999931 \n",
      "\n",
      "Epoch 65\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999932 \n",
      "\n",
      "Epoch 66\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999933 \n",
      "\n",
      "Epoch 67\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999934 \n",
      "\n",
      "Epoch 68\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999935 \n",
      "\n",
      "Epoch 69\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999935 \n",
      "\n",
      "Epoch 70\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999936 \n",
      "\n",
      "Epoch 71\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999937 \n",
      "\n",
      "Epoch 72\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999938 \n",
      "\n",
      "Epoch 73\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999939 \n",
      "\n",
      "Epoch 74\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999939 \n",
      "\n",
      "Epoch 75\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999940 \n",
      "\n",
      "Epoch 76\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999941 \n",
      "\n",
      "Epoch 77\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999941 \n",
      "\n",
      "Epoch 78\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999942 \n",
      "\n",
      "Epoch 79\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999943 \n",
      "\n",
      "Epoch 80\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -0.999999  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999943 \n",
      "\n",
      "Epoch 81\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999944 \n",
      "\n",
      "Epoch 82\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999945 \n",
      "\n",
      "Epoch 83\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999945 \n",
      "\n",
      "Epoch 84\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999946 \n",
      "\n",
      "Epoch 85\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999946 \n",
      "\n",
      "Epoch 86\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999947 \n",
      "\n",
      "Epoch 87\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999947 \n",
      "\n",
      "Epoch 88\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999948 \n",
      "\n",
      "Epoch 89\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999948 \n",
      "\n",
      "Epoch 90\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999949 \n",
      "\n",
      "Epoch 91\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999949 \n",
      "\n",
      "Epoch 92\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999950 \n",
      "\n",
      "Epoch 93\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999950 \n",
      "\n",
      "Epoch 94\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999998  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999951 \n",
      "\n",
      "Epoch 95\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999999  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999951 \n",
      "\n",
      "Epoch 96\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999999  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999952 \n",
      "\n",
      "Epoch 97\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999999  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999952 \n",
      "\n",
      "Epoch 98\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999999  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999953 \n",
      "\n",
      "Epoch 99\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999999  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999953 \n",
      "\n",
      "Epoch 100\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999999  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999954 \n",
      "\n",
      "Epoch 101\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999999  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999954 \n",
      "\n",
      "Epoch 102\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999999  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999954 \n",
      "\n",
      "Epoch 103\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999999  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999955 \n",
      "\n",
      "Epoch 104\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999999  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999955 \n",
      "\n",
      "Epoch 105\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999999  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999956 \n",
      "\n",
      "Epoch 106\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999999  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999956 \n",
      "\n",
      "Epoch 107\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999999  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999956 \n",
      "\n",
      "Epoch 108\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999999  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999957 \n",
      "\n",
      "Epoch 109\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999999  [12864/37138]\n",
      "loss: -1.000000  [19264/37138]\n",
      "loss: -1.000000  [25664/37138]\n",
      "loss: -1.000000  [32064/37138]\n",
      "Test Error: \n",
      " Accuracy: 50.1%, Avg loss: -0.999957 \n",
      "\n",
      "Epoch 110\n",
      "-------------------------------\n",
      "loss: -1.000000  [   64/37138]\n",
      "loss: -1.000000  [ 6464/37138]\n",
      "loss: -0.999999  [12864/37138]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m-------------------------------\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms17_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     test(s17_test_loader, model, loss_fn)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[37], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      2\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataloader\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[0;32m      3\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m----> 4\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Compute prediction error\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\bmost\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\bmost\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\bmost\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[1;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bmost\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:277\u001b[0m, in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[0;32m    217\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    Take in a batch of data and put the elements within the batch into a tensor with an additional outer dimension - batch size.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\bmost\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:144\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    141\u001b[0m transposed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mbatch))  \u001b[38;5;66;03m# It may be accessed twice, so we use a list.\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m samples \u001b[38;5;129;01min\u001b[39;00m transposed]  \u001b[38;5;66;03m# Backwards compatibility.\u001b[39;00m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\bmost\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:121\u001b[0m, in \u001b[0;36mcollate\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m--> 121\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m    124\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[1;32mc:\\Users\\bmost\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py:174\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[1;34m(batch, collate_fn_map)\u001b[0m\n\u001b[0;32m    172\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    173\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[1;32m--> 174\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(s17_train_loader, model, loss_fn, optimizer)\n",
    "    test(s17_test_loader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (tower_embedding): Sequential(\n",
       "    (0): Embedding(22, 3)\n",
       "  )\n",
       "  (hero_embedding): Sequential(\n",
       "    (0): Embedding(20, 3)\n",
       "  )\n",
       "  (map_embedding): Sequential(\n",
       "    (0): Embedding(21, 3)\n",
       "  )\n",
       "  (linear_sigm): Sequential(\n",
       "    (0): Linear(in_features=15, out_features=1, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([16,  1,  4,  7,  1,  1,  1, 13, 20])\n",
      "tensor([0.4962], grad_fn=<ViewBackward0>)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "ind = random.randint(0,len(s17_train)-1)\n",
    "pred = model(s17_train[ind][0].reshape(1,9))\n",
    "print(s17_train[ind][0])\n",
    "print(pred)\n",
    "print(s17_train[ind][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  1,  7, 20, 16,  1,  6, 19, 15]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s17_train[5000][0].reshape(1,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18,  8])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s17_test[0][0][0:2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
